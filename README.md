# WashU Master Project: Adversarial Attacks on Graph Embeddings Based on Text Dataset (FL2023)

## Abstract

This study delves into the intriguing domain of graph data vulnerability, specifically exploring the transformation from textual datasets to graph representations. Central to our investigation is the examination of the susceptibility of graph data to adversarial attacks. Contrasting with state-of-the-art approaches like Netattack and Meta Attack, which target both node attributes and graph structure, our experimental focus is primarily on attacking node embeddings.

Through empirical experimentation, we assess the effectiveness of both decision-time and poisoning attacks on graph neural networks. A significant finding of our study is that decision-time attacks employing Projected Gradient Descent (PGD) demonstrate greater efficacy compared to poisoning attacks that utilize Mean Node Embeddings and Graph Contrastive Learning. This insight contributes to the broader understanding of graph data security, highlighting critical areas where graph-based models are most vulnerable and paving the way for the development of more robust defenses.

Our research is supported by a comprehensive code repository, which includes all scripts and data used in our experiments. This repository is openly accessible and can be found at \href{https://github.com/YingXu001/Attack_Graph}{https://github.com/YingXu001/Attack\_Graph}, providing a valuable resource for further exploration and development in the field of graph data security.
